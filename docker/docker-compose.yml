zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
      - "2888:2888"
      - "3888:3888"

kafka:
    image: wurstmeister/kafka:0.9.0.1
    container_name: kafka
    ports:
      - "9092:9092"
      - "9999:9999"
    links:
      - zookeeper
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 100.0.0.205
      KAFKA_CREATE_TOPICS: "eventor_webserver:20:1"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 1
      KAFKA_MESSAGE_MAX_BYTES: 50000000
      KAFKA_REPLICA_FETCH_MAX_BYTES: 100000000
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 100000000
      KAFKA_NUM_PARTITIONS: 8
      JMX_PORT: 9999
      #KAFKA_HEAP_OPTS: "-Xmx2G -Xms2G"
      #KAFKA_JVM_PERFORMANCE_OPTS: "-XX:MaxPermSize=48M -verbose:gc -Xloggc:/var/log/kafka/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -XX:+PrintTLAB -XX:+DisableExplicitGC -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -XX:+UseCompressedOops -XX:+AlwaysPreTouch -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/log/kafka/heapDump.log"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

kafka_manager:
    image: sheepkiller/kafka-manager:1.3.1.6
    container_name: kafka_manager
    hostname: kafka_manager
    links:
      - zookeeper
      - kafka
    ports:
      - "9000:9000"
    environment:
      ZK_HOSTS: "zookeeper:2181"
      KM_VERSION: "1.3.1.6"
      KM_REVISION: "6cf43e383377a6b37df4faa04d9aff515a265b30"

eventor_webserver:
    container_name: eventor_webserver
    build: eventor_webserver
    hostname: eventor_webserver
    links:
       - kafka
    ports:
       - 80:80
    environment:
      FLUME_CONF_FILE: /opt/flume/conf/flume.conf
      FLUME_AGENT_NAME: a1
      FLUME_PLUGINS_DIRECTORY: /opt/flume/plugins.d/
      FLUME_JAVA_OPTIONS: "-Xms1024m -Xmx2048m -Xss256k -XX:MaxDirectMemorySize=256m -XX:+UseParNewGC -XX:+UseConcMarkSweepGC"

elasticsearch:
    image: elasticsearch:2.2.1
    container_name: elasticsearch
    hostname: elasticsearch
    environment:
      ES_HEAP_SIZE: "1g"
      ES_HEAP_NEWSIZE: "512m"
      ES_MIN_MEM: "512m"
      ES_MAX_MEM: "2g"
    ports:
      - 9200:9200
      - 9300:9300
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
      - ./elasticsearch/config/logging.yml:/usr/share/elasticsearch/config/logging.yml

kibana:
    image: kibana:4.4.1
    container_name: kibana
    hostname: kibana
    ports:
      - 5601:5601
    links:
      - elasticsearch

jobmanager:
    build: flink
    container_name: jobmanager
    ports:
      - 48080:8080
      - 6123:6123
    expose:
      - 22
    command: /usr/local/flink/bin/config-flink.sh jobmanager
    links:
      - kafka
      - elasticsearch
      - zookeeper
worker:
    build: flink
    container_name: worker
    expose:
      - 6121
      - 6122
    ports:
      - 6121:6121
      - 6122:6122
    links:
      - jobmanager
      - kafka
      - elasticsearch
    command: /usr/local/flink/bin/config-flink.sh taskmanager

locust:
    container_name: locust
    build: locust
    hostname: locust
    links:
      - eventor_webserver
    ports:
      - 8089:8089
    environment:
      TARGET_URL: "http://100.0.0.205/"